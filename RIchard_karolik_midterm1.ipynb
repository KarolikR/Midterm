{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://en.wikipedia.org/wiki/20th_Century%27s_Greatest_Hits:_100_English-Language_Books_of_Fiction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoup(link):\n",
    "    r = requests.get(link)\n",
    "    r.encoding = 'UTF-8'\n",
    "    return BeautifulSoup(r.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Nineteen_Eighty-Four',\n",
       " 'https://en.wikipedia.org/wiki/The_Ambassadors',\n",
       " 'https://en.wikipedia.org/wiki/An_American_Tragedy',\n",
       " 'https://en.wikipedia.org/wiki/Brave_New_World',\n",
       " 'https://en.wikipedia.org/wiki/Catch-22',\n",
       " 'https://en.wikipedia.org/wiki/The_Catcher_in_the_Rye',\n",
       " 'https://en.wikipedia.org/wiki/A_Clockwork_Orange_(novel)',\n",
       " 'https://en.wikipedia.org/wiki/The_Day_of_the_Locust',\n",
       " 'https://en.wikipedia.org/wiki/Finnegans_Wake',\n",
       " 'https://en.wikipedia.org/wiki/The_Grapes_of_Wrath',\n",
       " 'https://en.wikipedia.org/wiki/The_Great_Gatsby',\n",
       " 'https://en.wikipedia.org/wiki/Heart_of_Darkness',\n",
       " 'https://en.wikipedia.org/wiki/The_House_of_Mirth',\n",
       " 'https://en.wikipedia.org/wiki/Invisible_Man',\n",
       " 'https://en.wikipedia.org/wiki/Ironweed_(novel)',\n",
       " 'https://en.wikipedia.org/wiki/Lolita',\n",
       " 'https://en.wikipedia.org/wiki/Midnight%27s_Children',\n",
       " 'https://en.wikipedia.org/wiki/The_Naked_and_the_Dead',\n",
       " 'https://en.wikipedia.org/wiki/Native_Son',\n",
       " 'https://en.wikipedia.org/wiki/On_the_Road',\n",
       " 'https://en.wikipedia.org/wiki/Pale_Fire',\n",
       " 'https://en.wikipedia.org/wiki/A_Passage_to_India',\n",
       " 'https://en.wikipedia.org/wiki/A_Portrait_of_the_Artist_as_a_Young_Man',\n",
       " 'https://en.wikipedia.org/wiki/The_Sheltering_Sky',\n",
       " 'https://en.wikipedia.org/wiki/Slaughterhouse-Five',\n",
       " 'https://en.wikipedia.org/wiki/The_Sound_and_the_Fury',\n",
       " 'https://en.wikipedia.org/wiki/The_Sun_Also_Rises',\n",
       " 'https://en.wikipedia.org/wiki/To_the_Lighthouse',\n",
       " 'https://en.wikipedia.org/wiki/Tropic_of_Cancer_(novel)',\n",
       " 'https://en.wikipedia.org/wiki/Ulysses_(novel)',\n",
       " 'https://en.wikipedia.org/wiki/Under_the_Volcano',\n",
       " 'https://en.wikipedia.org/wiki/U.S.A._(trilogy)',\n",
       " 'https://en.wikipedia.org/wiki/Winesburg,_Ohio',\n",
       " 'https://en.wikipedia.org/wiki/Women_in_Love']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAllLinks(link):\n",
    "    soup = getSoup(link)\n",
    "    tds = soup.findAll('ol')[0].findAll('li')\n",
    "    return ['https://en.wikipedia.org' + td.find('a')['href'] for td in tds]\n",
    "\n",
    "links = getAllLinks(\"https://en.wikipedia.org/wiki/20th_Century%27s_Greatest_Hits:_100_English-Language_Books_of_Fiction\")\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1984',\n",
       " 'The Ambassadors',\n",
       " 'An American Tragedy',\n",
       " 'Brave New World',\n",
       " 'Catch-22',\n",
       " 'The Catcher in the Rye',\n",
       " 'A Clockwork Orange',\n",
       " 'The Day of the Locust',\n",
       " 'Finnegans Wake',\n",
       " 'The Grapes of Wrath',\n",
       " 'The Great Gatsby',\n",
       " 'Heart of Darkness',\n",
       " 'The House of Mirth',\n",
       " 'Invisible Man',\n",
       " 'Ironweed',\n",
       " 'Lolita',\n",
       " \"Midnight's Children\",\n",
       " 'The Naked and the Dead',\n",
       " 'Native Son',\n",
       " 'On the Road',\n",
       " 'Pale Fire',\n",
       " 'A Passage to India',\n",
       " 'A Portrait of the Artist as a Young Man',\n",
       " 'The Sheltering Sky',\n",
       " 'Slaughterhouse-Five',\n",
       " 'The Sound and the Fury',\n",
       " 'The Sun Also Rises',\n",
       " 'To the Lighthouse',\n",
       " 'Tropic of Cancer',\n",
       " 'Ulysses',\n",
       " 'Under the Volcano',\n",
       " 'The USA Trilogy',\n",
       " 'Winesburg, Ohio',\n",
       " 'Women in Love']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getBookNames(link):\n",
    "    soup = getSoup(link)\n",
    "    books = soup.findAll('ol')[0].findAll('li')\n",
    "    booknames = [name.find('a').text for name in books]\n",
    "    return booknames\n",
    "\n",
    "names = getBookNames(\"https://en.wikipedia.org/wiki/20th_Century%27s_Greatest_Hits:_100_English-Language_Books_of_Fiction\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Orwell\n"
     ]
    }
   ],
   "source": [
    "def getAuthorName(link):\n",
    "    soup_url = getSoup(link)\n",
    "    author = soup_url.findAll('table',{'class':'infobox vcard'})[0].findAll('td')[1]\n",
    "    author_name = author.text\n",
    "    print(author_name)\n",
    "\n",
    "getAuthorName('https://en.wikipedia.org/wiki/Nineteen_Eighty-Four')\n",
    "        \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Orwell\n",
      "Henry James\n",
      "Theodore Dreiser\n",
      "Aldous Huxley\n",
      "Joseph Heller\n",
      "J. D. Salinger\n",
      "Anthony Burgess\n",
      "Nathanael West\n",
      "James Joyce\n",
      "John Steinbeck\n",
      "F. Scott Fitzgerald\n",
      "Joseph Conrad\n",
      "Edith Wharton\n",
      "Ralph Ellison\n",
      "William Kennedy\n",
      "Vladimir Nabokov\n",
      "Salman Rushdie\n",
      "Norman Mailer\n",
      "Richard Wright\n",
      "Jack Kerouac\n",
      "Vladimir Nabokov\n",
      "E. M. Forster\n",
      "James Joyce\n",
      "Paul Bowles\n",
      "Kurt Vonnegut\n",
      "William Faulkner\n",
      "Author non-available\n",
      "Virginia Woolf\n",
      "Henry Miller\n",
      "James Joyce\n",
      "Malcolm Lowry\n",
      "John Dos Passos\n",
      "Sherwood Anderson\n",
      "D. H. Lawrence\n"
     ]
    }
   ],
   "source": [
    "### Scraping the author name from the descriptive table about book. In case of missing table output \n",
    "### will be \"Author non-available\"\n",
    "\n",
    "def getAuthorName(link):\n",
    "    soup_url = getSoup(link)\n",
    "    author = soup_url.findAll('table',{'class':'infobox vcard'})[0].findAll('td')[1]\n",
    "    author_name = author.text\n",
    "    print(author_name)\n",
    "\n",
    "for url_link in links:\n",
    "    try:\n",
    "        getAuthorName(url_link)\n",
    "    except:\n",
    "        print(\"Author non-available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class downloader used to scrape wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scraper:\n",
    "    \n",
    "    def __init__(self, allowLog = True):\n",
    "        ''' \n",
    "        Initialization of the basics of the downloader object, as well as defining of dataframes what supose to be output\n",
    "        of this downloader\n",
    "        '''\n",
    " \n",
    "        self.allowLog = allowLog\n",
    "        self.booknames = pd.DataFrame()\n",
    "        self.author = pd.DataFrame()\n",
    "        self.booklinks = []\n",
    "        if self.allowLog:\n",
    "            print('Downloader initialized.')\n",
    "        \n",
    "        \n",
    "    def getSoup(self, link):\n",
    "        ''' \n",
    "        This function is used to get request for he 'lxml' code of the webside and the parse the code to be used in next \n",
    "        part for scraping specific data\n",
    "        ''' \n",
    "        \n",
    "        self.link = link\n",
    "        r = requests.get(link)\n",
    "        r.encoding = 'UTF-8'\n",
    "        self.soup = BeautifulSoup(r.text,'lxml')\n",
    "        \n",
    "     \n",
    "    def getAllLinks(self):\n",
    "        ''' \n",
    "        Function used to get links of all books in which we are intrested in. I will use this URLs to get to the webside of \n",
    "        the book and then scrape more information (author name)\n",
    "        ''' \n",
    "        \n",
    "        booklinks = []\n",
    "        soup = getSoup(self.link)\n",
    "        tds = soup.findAll('ol')[0].findAll('li')\n",
    "        links = ['https://en.wikipedia.org' + td.find('a')['href'] for td in tds]\n",
    "        for i in links:\n",
    "            booklinks.append(i)\n",
    "            self.booklinks = booklinks\n",
    "\n",
    "    def getBookNames(self):\n",
    "        ''' \n",
    "        Function used to get names of the all books what should be scraped\n",
    "        '''\n",
    "        \n",
    "        soup = getSoup(self.link)\n",
    "        books = soup.findAll('ol')[0].findAll('li')\n",
    "        booknames = [name.find('a').text for name in books]\n",
    "        self.booknames = booknames\n",
    "\n",
    "    def getAuthorName(self):\n",
    "        '''\n",
    "        Scraping the author name from the descriptive table about book. In case of missing table output\n",
    "        will be \"Author non-available\"\n",
    "        '''\n",
    "        for i in self.booklinks:\n",
    "            try:\n",
    "                soup_url = getSoup(link)\n",
    "                author = soup_url.findAll('table',{'class':'infobox vcard'})[0].findAll('td')[1]\n",
    "                self.author = author.text\n",
    "            except:\n",
    "                self.author = \"Author non-available\"\n",
    "    \n",
    "    def saveDF(self): \n",
    "        '''\n",
    "       Saving scraped data as a dataframe using pandas.\n",
    "        '''\n",
    "        df = {}\n",
    "        df['Name of a book'] = self.booknames\n",
    "        df['Author'] = self.author  \n",
    "        self.result = df\n",
    "        return self.result\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scraper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-f49279cd1917>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scraper' is not defined"
     ]
    }
   ],
   "source": [
    "test = scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tu som sa zasekol a už som nemal čas, ďakujem za opravný termín aj keď som bol ako jediný."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.getSoup(\"https://en.wikipedia.org/wiki/20th_Century%27s_Greatest_Hits:_100_English-Language_Books_of_Fiction\")\n",
    "test.getAllLinks()\n",
    "test.getBookNames()\n",
    "test.getAuthorName()\n",
    "test.saveDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.booklinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.booknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
